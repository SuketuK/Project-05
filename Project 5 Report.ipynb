{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Domain and Data\n",
    " \n",
    "Prepared for the Neural Information Processing Symposium 2003 Feature Extraction Workshop\n",
    "\n",
    "http://clopinet.com/isabelle/Projects/NIPS2003\n",
    "\n",
    "### Data \n",
    "\n",
    "MADELON is an artificial dataset, which was part of the NIPS 2003 feature selection challenge. This is a two-class classification problem with continuous input variables. The difficulty is that the problem is multivariate and highly non-linear.\n",
    "\n",
    "MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. \n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "The NIPS 2003 challenge in feature selection is to find feature selection algorithms that significantly outperform methods using all features in performing a binary classification task.\n",
    "\n",
    "### Solution Statement\n",
    "\n",
    "We will develop a binary classification model and attempt to augment its performance using automatic feature selection techniques.\n",
    "\n",
    "### Metric\n",
    "\n",
    "We will use accuracy score for comparing models.\n",
    "\n",
    "### Benchmark\n",
    "\n",
    "We will use as a benchmark our mean accuracy across five random train test splits using a K Nearest Neighbors model with an optimal value for number of `n_neighbors`. This model had a 73.8% accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result from Step 1 from Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the naive LogisticRegression it appears that model worked very well on train set however performed poorly on the test data set. ** The train score was perfectly 1.0 and test data score dcid poorly 0.544 **. This suggest we need to further tune the model with more penaly or even performing LogisticRegression using Lasso method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result from Step 2 Identify Salient Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran 6 models with LogisticRegression. ** With penalty Lasso and C value as 0.027 we found the highest test score with 8 features.** We will use this model and compare that against other models e.g. SelectKBest, KNN and GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://localhost:8888/notebooks/dsi/dsi-workspace/project-05/images/salient_features_step2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from Step 3 Build the model\n",
    "\n",
    "I built multiple models using GridSearch classifier with Logistic Regression and KNN models. \n",
    "First I construct pipeline to run on GridSearch with Logistic Regression \n",
    "    1. Build a new pipeline for LogisticRegression.\n",
    "    2. Ran model on L1 and L2\n",
    "    3. With Regularization 0.01, .1, .2, 0.03\n",
    "    4. Run 5 Fold Grid Serach\n",
    "    5. Review the Score\n",
    "Then I Construct a pipeline that uses SelectKBest, KNN and ran on GridSearch classifer\n",
    "    1. Build a new pipeline for SelectKBest and KNN.\n",
    "    2. Set the neighbors between 11 and 21\n",
    "    3. Select the max of 10 features using SelectKBest\n",
    "    4. Run 5 Fold Grid Serach\n",
    "    5. Review the Score\n",
    "    6. Compare with LogisticRegression Score\n",
    "    7. Review features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN/SelectKBest is significantly higher and we will use that for the model. See below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Best Model (Total 8 models Ran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://localhost:8888/notebooks/dsi/dsi-workspace/project-05/images/LR_Model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Best Model (Total 6 models Ran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://localhost:8888/notebooks/dsi/dsi-workspace/project-05/images/KNN_Model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recommendations: I would have liked to graph on the features to visually see which features might have better weight so that would be something I would like to explore, also with KNN I would like to continue to predict and see the Preceision, recall, F1 and support score for further tuning.  **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
