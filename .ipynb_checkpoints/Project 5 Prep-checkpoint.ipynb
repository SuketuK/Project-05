{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "#from os import chdir; chdir('..')\n",
    "#from os import chdir; chdir('./lib')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from project_5 import load_data_from_database, make_data_dict,general_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/src/dsi/dsi-workspace/project-05/lib\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_491</th>\n",
       "      <th>feat_492</th>\n",
       "      <th>feat_493</th>\n",
       "      <th>feat_494</th>\n",
       "      <th>feat_495</th>\n",
       "      <th>feat_496</th>\n",
       "      <th>feat_497</th>\n",
       "      <th>feat_498</th>\n",
       "      <th>feat_499</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>...</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  \\\n",
       "0      0       485       477       537       479       452       471   \n",
       "1      1       483       458       460       487       587       475   \n",
       "2      2       487       542       499       468       448       471   \n",
       "3      3       480       491       510       485       495       472   \n",
       "4      4       484       502       528       489       466       481   \n",
       "\n",
       "   feat_006  feat_007  feat_008  ...    feat_491  feat_492  feat_493  \\\n",
       "0       491       476       475  ...         481       477       485   \n",
       "1       526       479       485  ...         478       487       338   \n",
       "2       442       478       480  ...         481       492       650   \n",
       "3       417       474       502  ...         480       474       572   \n",
       "4       402       478       487  ...         479       452       435   \n",
       "\n",
       "   feat_494  feat_495  feat_496  feat_497  feat_498  feat_499  label  \n",
       "0       511       485       481       479       475       496     -1  \n",
       "1       513       486       483       492       510       517     -1  \n",
       "2       506       501       480       489       499       498     -1  \n",
       "3       454       469       475       482       494       461      1  \n",
       "4       486       508       481       504       495       511      1  \n",
       "\n",
       "[5 rows x 502 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madelon_df = load_data_from_database()\n",
    "madelon_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 502)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madelon_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_491</th>\n",
       "      <th>feat_492</th>\n",
       "      <th>feat_493</th>\n",
       "      <th>feat_494</th>\n",
       "      <th>feat_495</th>\n",
       "      <th>feat_496</th>\n",
       "      <th>feat_497</th>\n",
       "      <th>feat_498</th>\n",
       "      <th>feat_499</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>999.500000</td>\n",
       "      <td>481.722500</td>\n",
       "      <td>483.452500</td>\n",
       "      <td>510.166000</td>\n",
       "      <td>483.384500</td>\n",
       "      <td>501.612500</td>\n",
       "      <td>479.259000</td>\n",
       "      <td>480.109500</td>\n",
       "      <td>476.565000</td>\n",
       "      <td>486.793500</td>\n",
       "      <td>...</td>\n",
       "      <td>478.811500</td>\n",
       "      <td>486.356500</td>\n",
       "      <td>496.565500</td>\n",
       "      <td>493.49950</td>\n",
       "      <td>510.893000</td>\n",
       "      <td>478.219500</td>\n",
       "      <td>483.309000</td>\n",
       "      <td>507.977000</td>\n",
       "      <td>490.266000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>6.421769</td>\n",
       "      <td>30.186294</td>\n",
       "      <td>38.899165</td>\n",
       "      <td>9.059895</td>\n",
       "      <td>41.389418</td>\n",
       "      <td>6.795956</td>\n",
       "      <td>40.575925</td>\n",
       "      <td>1.384461</td>\n",
       "      <td>15.043836</td>\n",
       "      <td>...</td>\n",
       "      <td>4.011735</td>\n",
       "      <td>23.967366</td>\n",
       "      <td>127.635442</td>\n",
       "      <td>34.81902</td>\n",
       "      <td>37.459353</td>\n",
       "      <td>5.880613</td>\n",
       "      <td>13.559847</td>\n",
       "      <td>37.224297</td>\n",
       "      <td>25.825273</td>\n",
       "      <td>1.00025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>471.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>368.00000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>457.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>363.000000</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>499.750000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>485.000000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>452.750000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>471.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>470.00000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>999.500000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>483.000000</td>\n",
       "      <td>510.500000</td>\n",
       "      <td>483.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>479.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>479.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>492.00000</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>483.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1499.250000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>503.000000</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>506.250000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>496.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>502.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>517.00000</td>\n",
       "      <td>535.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>507.250000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1999.000000</td>\n",
       "      <td>503.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>688.000000</td>\n",
       "      <td>505.000000</td>\n",
       "      <td>611.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>615.00000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>535.000000</td>\n",
       "      <td>644.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index     feat_000     feat_001     feat_002     feat_003  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean    999.500000   481.722500   483.452500   510.166000   483.384500   \n",
       "std     577.494589     6.421769    30.186294    38.899165     9.059895   \n",
       "min       0.000000   462.000000   381.000000   370.000000   453.000000   \n",
       "25%     499.750000   477.000000   464.000000   485.000000   477.000000   \n",
       "50%     999.500000   482.000000   483.000000   510.500000   483.000000   \n",
       "75%    1499.250000   486.000000   503.000000   536.000000   490.000000   \n",
       "max    1999.000000   503.000000   600.000000   654.000000   519.000000   \n",
       "\n",
       "          feat_004     feat_005     feat_006     feat_007     feat_008  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean    501.612500   479.259000   480.109500   476.565000   486.793500   \n",
       "std      41.389418     6.795956    40.575925     1.384461    15.043836   \n",
       "min     371.000000   459.000000   334.000000   471.000000   430.000000   \n",
       "25%     475.000000   475.000000   452.750000   476.000000   477.000000   \n",
       "50%     500.000000   479.000000   480.000000   477.000000   487.000000   \n",
       "75%     528.000000   484.000000   506.250000   477.000000   496.250000   \n",
       "max     688.000000   505.000000   611.000000   481.000000   536.000000   \n",
       "\n",
       "          ...         feat_491     feat_492     feat_493    feat_494  \\\n",
       "count     ...      2000.000000  2000.000000  2000.000000  2000.00000   \n",
       "mean      ...       478.811500   486.356500   496.565500   493.49950   \n",
       "std       ...         4.011735    23.967366   127.635442    34.81902   \n",
       "min       ...       463.000000   391.000000   130.000000   368.00000   \n",
       "25%       ...       476.000000   471.000000   404.000000   470.00000   \n",
       "50%       ...       479.000000   486.000000   504.000000   492.00000   \n",
       "75%       ...       481.000000   502.000000   586.000000   517.00000   \n",
       "max       ...       497.000000   566.000000   920.000000   615.00000   \n",
       "\n",
       "          feat_495     feat_496     feat_497     feat_498     feat_499  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean    510.893000   478.219500   483.309000   507.977000   490.266000   \n",
       "std      37.459353     5.880613    13.559847    37.224297    25.825273   \n",
       "min     398.000000   457.000000   435.000000   363.000000   403.000000   \n",
       "25%     486.000000   474.000000   474.000000   482.000000   473.000000   \n",
       "50%     511.000000   478.000000   483.000000   508.000000   490.000000   \n",
       "75%     535.000000   482.000000   492.000000   533.000000   507.250000   \n",
       "max     661.000000   500.000000   535.000000   644.000000   583.000000   \n",
       "\n",
       "            label  \n",
       "count  2000.00000  \n",
       "mean      0.00000  \n",
       "std       1.00025  \n",
       "min      -1.00000  \n",
       "25%      -1.00000  \n",
       "50%       0.00000  \n",
       "75%       1.00000  \n",
       "max       1.00000  \n",
       "\n",
       "[8 rows x 502 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madelon_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dict= make_data_dict(madelon_df,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_490</th>\n",
       "      <th>feat_491</th>\n",
       "      <th>feat_492</th>\n",
       "      <th>feat_493</th>\n",
       "      <th>feat_494</th>\n",
       "      <th>feat_495</th>\n",
       "      <th>feat_496</th>\n",
       "      <th>feat_497</th>\n",
       "      <th>feat_498</th>\n",
       "      <th>feat_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>1738</td>\n",
       "      <td>481</td>\n",
       "      <td>462</td>\n",
       "      <td>564</td>\n",
       "      <td>482</td>\n",
       "      <td>484</td>\n",
       "      <td>478</td>\n",
       "      <td>493</td>\n",
       "      <td>476</td>\n",
       "      <td>509</td>\n",
       "      <td>...</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>460</td>\n",
       "      <td>612</td>\n",
       "      <td>485</td>\n",
       "      <td>557</td>\n",
       "      <td>476</td>\n",
       "      <td>488</td>\n",
       "      <td>633</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>548</td>\n",
       "      <td>481</td>\n",
       "      <td>496</td>\n",
       "      <td>494</td>\n",
       "      <td>478</td>\n",
       "      <td>461</td>\n",
       "      <td>474</td>\n",
       "      <td>484</td>\n",
       "      <td>477</td>\n",
       "      <td>478</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>478</td>\n",
       "      <td>474</td>\n",
       "      <td>532</td>\n",
       "      <td>517</td>\n",
       "      <td>507</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>505</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>936</td>\n",
       "      <td>495</td>\n",
       "      <td>525</td>\n",
       "      <td>551</td>\n",
       "      <td>478</td>\n",
       "      <td>544</td>\n",
       "      <td>483</td>\n",
       "      <td>507</td>\n",
       "      <td>475</td>\n",
       "      <td>511</td>\n",
       "      <td>...</td>\n",
       "      <td>460</td>\n",
       "      <td>490</td>\n",
       "      <td>502</td>\n",
       "      <td>656</td>\n",
       "      <td>554</td>\n",
       "      <td>553</td>\n",
       "      <td>465</td>\n",
       "      <td>503</td>\n",
       "      <td>520</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>1389</td>\n",
       "      <td>495</td>\n",
       "      <td>464</td>\n",
       "      <td>472</td>\n",
       "      <td>498</td>\n",
       "      <td>499</td>\n",
       "      <td>472</td>\n",
       "      <td>454</td>\n",
       "      <td>478</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>474</td>\n",
       "      <td>477</td>\n",
       "      <td>517</td>\n",
       "      <td>634</td>\n",
       "      <td>448</td>\n",
       "      <td>514</td>\n",
       "      <td>486</td>\n",
       "      <td>496</td>\n",
       "      <td>475</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>1607</td>\n",
       "      <td>477</td>\n",
       "      <td>472</td>\n",
       "      <td>544</td>\n",
       "      <td>483</td>\n",
       "      <td>457</td>\n",
       "      <td>476</td>\n",
       "      <td>526</td>\n",
       "      <td>474</td>\n",
       "      <td>482</td>\n",
       "      <td>...</td>\n",
       "      <td>501</td>\n",
       "      <td>474</td>\n",
       "      <td>499</td>\n",
       "      <td>477</td>\n",
       "      <td>524</td>\n",
       "      <td>567</td>\n",
       "      <td>476</td>\n",
       "      <td>484</td>\n",
       "      <td>503</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  \\\n",
       "1738   1738       481       462       564       482       484       478   \n",
       "548     548       481       496       494       478       461       474   \n",
       "936     936       495       525       551       478       544       483   \n",
       "1389   1389       495       464       472       498       499       472   \n",
       "1607   1607       477       472       544       483       457       476   \n",
       "\n",
       "      feat_006  feat_007  feat_008    ...     feat_490  feat_491  feat_492  \\\n",
       "1738       493       476       509    ...          478       478       460   \n",
       "548        484       477       478    ...          491       478       474   \n",
       "936        507       475       511    ...          460       490       502   \n",
       "1389       454       478       476    ...          474       477       517   \n",
       "1607       526       474       482    ...          501       474       499   \n",
       "\n",
       "      feat_493  feat_494  feat_495  feat_496  feat_497  feat_498  feat_499  \n",
       "1738       612       485       557       476       488       633       479  \n",
       "548        532       517       507       478       478       505       463  \n",
       "936        656       554       553       465       503       520       490  \n",
       "1389       634       448       514       486       496       475       525  \n",
       "1607       477       524       567       476       484       503       485  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['X_train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dict = general_transformer(StandardScaler(),data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformer = data_dict[\"transformer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.2789811 , -0.13882911, -0.72646228, ...,  0.35221659,\n",
       "         3.3450926 , -0.43164517],\n",
       "       [-0.78873069, -0.13882911,  0.41909385, ..., -0.37842216,\n",
       "        -0.0763225 , -1.04419743],\n",
       "       [-0.11455239,  2.08159081,  1.39618585, ...,  1.44817471,\n",
       "         0.32462458, -0.01051548],\n",
       "       ..., \n",
       "       [-0.24660793, -0.13882911,  0.28432254, ...,  0.86366371,\n",
       "         0.69884185, -1.04419743],\n",
       "       [ 0.79419825,  0.33697516,  1.12664323, ...,  1.95962184,\n",
       "        -0.79802725,  0.75517486],\n",
       "       [ 0.21558647,  0.97138085, -1.33293318, ...,  0.13302496,\n",
       "        -0.26343114,  1.21458906]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[\"X_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "#from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression,Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = madelon_df[\"label\"]\n",
    "X = madelon_df.drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size=0.33, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = linear_model.LogisticRegression(penalty = 'l1', C=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80597014925373134, 0.53636363636363638)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score,test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive top 13 coef_:        feature     coef_\n",
      "473  feat_472  0.681057\n",
      "434  feat_433  0.675260\n",
      "476  feat_475  0.550221\n",
      "49   feat_048  0.338703\n",
      "47   feat_046  0.328519\n",
      "57   feat_056  0.315169\n",
      "495  feat_494  0.284937\n",
      "413  feat_412  0.271571\n",
      "500  feat_499  0.270138\n",
      "425  feat_424  0.265853\n",
      "54   feat_053  0.263579\n",
      "16   feat_015  0.260616\n",
      "166  feat_165  0.250957\n",
      "341  feat_340  0.237023\n",
      "318  feat_317  0.231359\n",
      "152  feat_151  0.229718\n",
      "349  feat_348  0.225215\n",
      "34   feat_033  0.223729\n",
      "283  feat_282  0.216191\n",
      "295  feat_294  0.213273\n",
      "118  feat_117  0.212690\n",
      "187  feat_186  0.212565\n",
      "472  feat_471  0.211874\n",
      "334  feat_333  0.205392\n",
      "197  feat_196  0.202015\n",
      "269  feat_268  0.195580\n",
      "212  feat_211  0.195439\n",
      "362  feat_361  0.195058\n",
      "475  feat_474  0.193736\n",
      "321  feat_320  0.193334\n",
      "..        ...       ...\n",
      "267  feat_266  0.110467\n",
      "185  feat_184  0.109581\n",
      "327  feat_326  0.109104\n",
      "385  feat_384  0.104342\n",
      "210  feat_209  0.103752\n",
      "102  feat_101  0.102291\n",
      "55   feat_054  0.101734\n",
      "173  feat_172  0.101012\n",
      "138  feat_137  0.100141\n",
      "453  feat_452  0.098695\n",
      "488  feat_487  0.098241\n",
      "115  feat_114  0.097968\n",
      "310  feat_309  0.095474\n",
      "371  feat_370  0.095309\n",
      "150  feat_149  0.094959\n",
      "313  feat_312  0.094561\n",
      "284  feat_283  0.094220\n",
      "479  feat_478  0.093160\n",
      "145  feat_144  0.092453\n",
      "165  feat_164  0.092424\n",
      "386  feat_385  0.090762\n",
      "353  feat_352  0.090272\n",
      "19   feat_018  0.090030\n",
      "399  feat_398  0.087935\n",
      "25   feat_024  0.087612\n",
      "494  feat_493  0.086550\n",
      "403  feat_402  0.085514\n",
      "204  feat_203  0.084899\n",
      "350  feat_349  0.084620\n",
      "214  feat_213  0.084350\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "Negative top 10 coef_:        feature     coef_\n",
      "443  feat_442 -1.000722\n",
      "154  feat_153 -0.746425\n",
      "358  feat_357 -0.314218\n",
      "497  feat_496 -0.312612\n",
      "6    feat_005 -0.280661\n",
      "414  feat_413 -0.279855\n",
      "426  feat_425 -0.276306\n",
      "162  feat_161 -0.275576\n",
      "311  feat_310 -0.256957\n",
      "131  feat_130 -0.256360\n",
      "262  feat_261 -0.241586\n",
      "424  feat_423 -0.241148\n",
      "286  feat_285 -0.234677\n",
      "297  feat_296 -0.229766\n",
      "319  feat_318 -0.229758\n",
      "35   feat_034 -0.224495\n",
      "169  feat_168 -0.217864\n",
      "279  feat_278 -0.216228\n",
      "64   feat_063 -0.215820\n",
      "470  feat_469 -0.215672\n",
      "418  feat_417 -0.215215\n",
      "66   feat_065 -0.209226\n",
      "282  feat_281 -0.209141\n",
      "287  feat_286 -0.207574\n",
      "335  feat_334 -0.204420\n",
      "61   feat_060 -0.196192\n",
      "116  feat_115 -0.190426\n",
      "227  feat_226 -0.184706\n",
      "421  feat_420 -0.183347\n",
      "408  feat_407 -0.177635\n",
      "..        ...       ...\n",
      "324  feat_323 -0.120512\n",
      "110  feat_109 -0.119486\n",
      "90   feat_089 -0.116830\n",
      "496  feat_495 -0.115399\n",
      "168  feat_167 -0.113778\n",
      "206  feat_205 -0.113023\n",
      "493  feat_492 -0.111824\n",
      "484  feat_483 -0.111762\n",
      "278  feat_277 -0.111455\n",
      "487  feat_486 -0.111397\n",
      "46   feat_045 -0.110936\n",
      "157  feat_156 -0.109187\n",
      "292  feat_291 -0.109096\n",
      "56   feat_055 -0.108809\n",
      "199  feat_198 -0.106751\n",
      "481  feat_480 -0.106420\n",
      "139  feat_138 -0.103376\n",
      "236  feat_235 -0.102859\n",
      "480  feat_479 -0.102731\n",
      "127  feat_126 -0.102034\n",
      "219  feat_218 -0.101996\n",
      "394  feat_393 -0.101785\n",
      "10   feat_009 -0.098326\n",
      "490  feat_489 -0.097998\n",
      "344  feat_343 -0.097600\n",
      "320  feat_319 -0.095992\n",
      "94   feat_093 -0.095506\n",
      "307  feat_306 -0.095071\n",
      "80   feat_079 -0.094198\n",
      "15   feat_014 -0.092045\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_coef = []\n",
    "for i,k in enumerate(X.columns):\n",
    "    feature_coef.append([k, model.coef_[0][i]])\n",
    "df_coef=pd.DataFrame(feature_coef)\n",
    "df_coef.columns = [\"feature\",\"coef_\"]\n",
    "print \"Positive top 13 coef_: \", df_coef.sort_values([\"coef_\"],ascending=False).head(100)\n",
    "print \"Negative top 10 coef_: \", df_coef.sort_values([\"coef_\"]).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.77313432835820894, 0.55454545454545456)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size=0.33, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = linear_model.LogisticRegression(penalty = 'l1', C=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "train_score,test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive top 13 coef_:        feature     coef_\n",
      "476  feat_475  0.391493\n",
      "49   feat_048  0.291718\n",
      "425  feat_424  0.157256\n",
      "47   feat_046  0.144166\n",
      "495  feat_494  0.133353\n",
      "54   feat_053  0.130533\n",
      "57   feat_056  0.119123\n",
      "205  feat_204  0.112530\n",
      "212  feat_211  0.111803\n",
      "413  feat_412  0.105350\n",
      "Negative top 10 coef_:        feature     coef_\n",
      "297  feat_296 -0.140488\n",
      "497  feat_496 -0.120720\n",
      "6    feat_005 -0.118236\n",
      "426  feat_425 -0.113567\n",
      "64   feat_063 -0.112343\n",
      "162  feat_161 -0.103527\n",
      "200  feat_199 -0.103137\n",
      "131  feat_130 -0.098235\n",
      "424  feat_423 -0.092128\n",
      "279  feat_278 -0.091646\n"
     ]
    }
   ],
   "source": [
    "feature_coef = []\n",
    "for i,k in enumerate(X.columns):\n",
    "    feature_coef.append([k, model.coef_[0][i]])\n",
    "df_coef=pd.DataFrame(feature_coef)\n",
    "df_coef.columns = [\"feature\",\"coef_\"]\n",
    "print \"Positive top 13 coef_: \", df_coef.sort_values([\"coef_\"],ascending=False).head(10)\n",
    "print \"Negative top 10 coef_: \", df_coef.sort_values([\"coef_\"]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.62313432835820892, 0.59696969696969693)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size=0.33, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = linear_model.LogisticRegression(penalty = 'l1', C=0.0185)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "train_score,test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive top 6 coef_:        feature     coef_\n",
      "476  feat_475  0.262432\n",
      "49   feat_048  0.127159\n",
      "242  feat_241  0.025942\n",
      "330  feat_329  0.012578\n",
      "425  feat_424  0.000568\n",
      "340  feat_339  0.000000\n"
     ]
    }
   ],
   "source": [
    "feature_coef = []\n",
    "for i,k in enumerate(X.columns):\n",
    "    feature_coef.append([k, model.coef_[0][i]])\n",
    "df_coef=pd.DataFrame(feature_coef)\n",
    "df_coef.columns = [\"feature\",\"coef_\"]\n",
    "print \"Positive top 6 coef_: \", df_coef.sort_values([\"coef_\"],ascending=False).head(6)\n",
    "#print \"Negative top 5 coef_: \", df_coef.sort_values([\"coef_\"]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def general_classifier(X, y, model, random_state):\n",
    "    \n",
    "    X_train,     \\\n",
    "        X_test,  \\\n",
    "        y_train, \\\n",
    "        y_test = train_test_split(X, y,random_state=random_state)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    return {'model' : model,\n",
    "            'train_score' : train_score,\n",
    "            'test_score' : test_score}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_pipeline = (\n",
    "    SelectKBest(f_classif, k=5),\n",
    "    KNeighborsClassifier(n_neighbors=17)\n",
    ")\n",
    "general_classifier(X,\n",
    "                   y,\n",
    "                    SelectKBest(f_classif, k=5), 42)\n",
    "via_make = make_pipeline(*this_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 49,  65, 242, 337, 476])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(X, y,random_state=42)\n",
    "\n",
    "this = SelectKBest(f_classif, k=5)\n",
    "this.fit_transform(X_train,y_train)\n",
    "this.get_support(indices=True)\n",
    "this.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
